{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload configuration\n",
    "---------\n",
    "First reload everything as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import regressiondemo as rd\n",
    "\n",
    "##############################\n",
    "#      Customize the demo here\n",
    "#      =======================\n",
    "# the \"true\" function of x with range fixed at [0,10]\n",
    "def truefunc(x):\n",
    "    return numpy.sin(x*2.0)*numpy.sqrt(numpy.absolute(x))/3.3\n",
    "\n",
    "#  when fitting goes wild, need to constrain what y's are plotted\n",
    "#  must be compatible with \"true\" function\n",
    "ydisplaymin = -1.8\n",
    "ydisplaymax = 1.8\n",
    "\n",
    "#  don't make points more than 100 as demo is O(points^3)\n",
    "points = 30\n",
    "\n",
    "#  noise level (std.dev)\n",
    "rd.setSigma(0.2)\n",
    "##############################\n",
    "\n",
    "\n",
    "x = rd.makeX(points)\n",
    "#  build the true values matching the sampled data\n",
    "y = rd.addNoise(truefunc(x))\n",
    "\n",
    "# xts and yts store the \"true\" function for the purposes of plotting\n",
    "# these have to be high frequency to make the resultant plot look\n",
    "# like a smooth curve\n",
    "xts = rd.makeX(200,uniform=True)\n",
    "yts = truefunc(xts)\n",
    "\n",
    "#  build a set of polynomial orders to use to fit\n",
    "orders = rd.makeOrders(points)\n",
    "\n",
    "# make canvas size a bit bigger (in inches)\n",
    "bigcanvas = [8,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ensemble of fits\n",
    "---------\n",
    "So we have seen how the two algorithms behave with different data sets of the same size.  So lets now fix the data set and ask a different question.  What different fits could reasonably match the finite sample of data we actually have?  This is a very important question in practice.  For learning, this is the classical \"what if\" scenario:  I don't know the real curve and only have a finite amount of data.  Within the assumptions of my algorithm, and fitting the data I have, what different fits are realistic?  What variability is there? What are range of possibilities? \n",
    "\n",
    "This is the motivation behind generating an *ensemble* of functions to match our data.  Averaging predictions over an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning) turns out to be one of the best ways of improving on a particular method for doing prediction.  What is needed is an additional method for generating the ensemble.\n",
    "\n",
    "Using statistical methods, we can attempt to create an ensemble in a number of ways:  working with random subsets of features; making some random choices in the algorithm, or using a variety of different algorithms.  Bayesian non-parametric methods generate ensembles relatively easily (in theory, that is).  One runs a simulation, a so-called, Monte Carlo sampler, to generate different fits.  We do this below.\n",
    "\n",
    "\n",
    "Step 4.1:  Testing ensembles\n",
    "-----------\n",
    "So rerun this plot with different data set sizes (*points*) to look at the ensembles produced.  Try from, say, 10 upwards and look at the change in variability of the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#      Customize the demo here\n",
    "#      =======================\n",
    "#  change points here if you want to see effect of different sample sizes\n",
    "points = 20\n",
    "samples = 10\n",
    "##############################\n",
    "\n",
    "# generate new data (x,y)\n",
    "order = rd.maxOrder(points)\n",
    "x = rd.makeX(points)\n",
    "y = rd.addNoise(truefunc(x))\n",
    "\n",
    "# make canvas size a bit bigger (in inches)\n",
    "pl.figure(figsize=bigcanvas)\n",
    "\n",
    "pl.plot(xts, yts,label = 'truth', linewidth=3.0)\n",
    "#   can be handy to modify the point size for data, \n",
    "#   use 2,4,6 depending on data set size\n",
    "pl.plot(x, y, 'o', markersize=6.0) \n",
    "pl.ylabel('y')\n",
    "pl.xlabel('x')\n",
    "        \n",
    "legpoly = rd.LegPoly(order)\n",
    "# we do the first fit as before, and plot it\n",
    "legpoly.fit(x,y)\n",
    "ys = legpoly.apply(xts)  \n",
    "pl.plot(xts, ys, linewidth=1.25 )  \n",
    "\n",
    "for i in range(samples):\n",
    "    # now, subsequently, we sample a new curve\n",
    "    legpoly.sample(y)\n",
    "    #  build the fitted poly curve \n",
    "    ys = legpoly.apply(xts)  \n",
    "\n",
    "    #  plot fitted curve\n",
    "    pl.plot(xts, ys, linewidth=1.25 )  \n",
    "    \n",
    "#  the y range for the plot has to be altered depending on the data\n",
    "pl.ylim(ydisplaymin,ydisplaymax)\n",
    "\n",
    "# move the legend out of the way\n",
    "# the (1.2, 1.2) starts the legend at the location relative to\n",
    "# the top right corner\n",
    "pl.legend(bbox_to_anchor=(1.3, 1.1))\n",
    "pl.suptitle('An ensemble of fits for order='+str(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "RegressionLegendreEnsemble.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
