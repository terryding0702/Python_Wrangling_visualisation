{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Reload configuration\n",
    "First reload everything as per earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import regressiondemo as rd\n",
    "\n",
    "##############################\n",
    "#      Customize the demo here\n",
    "#      =======================\n",
    "# the \"true\" function of x with range fixed at [0,10]\n",
    "def truefunc(x):\n",
    "    return numpy.sin(x*2.0)*numpy.sqrt(numpy.absolute(x))/3.3\n",
    "\n",
    "#  when fitting goes wild, need to constrain what y's are plotted\n",
    "#  must be compatible with \"true\" function\n",
    "ydisplaymin = -1.8\n",
    "ydisplaymax = 1.8\n",
    "\n",
    "#  noise level as std.dev\n",
    "rd.setSigma(0.2)\n",
    "#  don't make points more than 100 as demo is O(points^3)\n",
    "points = 30\n",
    "##############################\n",
    "\n",
    "# xts and yts store the \"true\" function for the purposes of plotting\n",
    "# these have to be high frequency to make the resultant plot look\n",
    "# like a smooth curve\n",
    "xts = rd.makeX(200,uniform=True)\n",
    "yts = truefunc(xts)\n",
    "\n",
    "#  build a set of polynomial orders to use to fit\n",
    "orders = rd.makeOrders(points)\n",
    "\n",
    "# make canvas size a bit bigger (in inches)\n",
    "bigcanvas = [8,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with Smoothed Legendre Polynomials\n",
    "============\n",
    "Now to complete this series of illustrations, lets make a better effort of linear regression.  Simple linear regression with powers is not very smart and self-respecting statisticians would only use it in two contexts:\n",
    "*  they have loads of data so the statistical fitting methods can be naive, or\n",
    "*  they need a quick and dirty solution, for instance implemented on limited hardware.\n",
    "\n",
    "One can do a much better.  There are many other methods one can use, and generally one needs a [non-parametric statistical](http://en.wikipedia.org/wiki/Nonparametric_statistics) method or a Bayesian non-parametric method.  These aren't constrained to a particular order of polynomial and attempt to fit complexity as needed. A popular technique here is to use [Gaussian processes](http://en.wikipedia.org/wiki/Gaussian_processes), which are a Bayesian non-parametric method.  \n",
    "\n",
    "We'll instead use a method using Smoothed Legendre Polynomials that is half-way between a Gaussian process and standard linear regression.  The details are not important for this demonstration but some details can be found in the other notebook \"RegressionLegendreDetail.ipynb\".  Legendre polynomial smoothing is designed for the case when our functions are \"smooth\" and tend to have less curvature on average.  \n",
    "\n",
    "\n",
    "Step 3.1:  Different orders of smoothed Legendre polynomials\n",
    "----------\n",
    "We'll start by fitting different orders of these just as we did above with the \"simple polynomials on different data\" plot previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#      Customize the plot here\n",
    "#      =======================\n",
    "#      grab last for orders to plot a 2X2\n",
    "fourorders = orders[-4:]\n",
    "#  fourorders = [3,6,10,20]\n",
    "points = 30\n",
    "#  data sets per plot to show\n",
    "setcount = 5\n",
    "##############################\n",
    "\n",
    "print ('Fitting polynomials of orders = ', fourorders)\n",
    "\n",
    "# make canvas size a bit bigger (in inches)\n",
    "pl.figure(figsize=bigcanvas)\n",
    "pl.suptitle( 'Smoothed Legendre Polynomials fit to different data of size '+str(points))\n",
    "sp = 1;\n",
    "for order in fourorders:\n",
    "    pl.subplot(2,2,sp)\n",
    "    sp += 1\n",
    "    #  plot the truth\n",
    "    pl.plot(xts, yts, linewidth=2) # default is green line? \n",
    "    #  be careful when we show the x/y axes\n",
    "    if sp>3:\n",
    "        pl.xlabel('x')\n",
    "    if sp%2==0:\n",
    "        pl.ylabel('y')\n",
    "    legpoly = rd.LegPoly(order)    \n",
    "    for s in range(setcount):\n",
    "        # generate another sample\n",
    "        xb = rd.makeX(points)\n",
    "        yb = rd.addNoise(truefunc(xb))\n",
    "        # fit the polynomial\n",
    "        legpoly.fit(xb, yb) \n",
    "        #  build the fitted poly curve \n",
    "        ys = legpoly.apply(xts)\n",
    "        #  plot fitted curve\n",
    "        pl.plot(xts, ys, linewidth=1.25 ) \n",
    "        \n",
    "    pl.title('Polys of order '+str(order))\n",
    "    \n",
    "    #  the y range for the plot has to be altered depending on the data\n",
    "    pl.ylim(ydisplaymin,ydisplaymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike standard linear regression, the fit doesn't start to go wild with higher orders of polynomials.  The fit has been \"smoothed\" at the higher orders.  So while for the lower orders, things look the same as with standard regression, for higher orders the fit generally keeps improving and the fitted polynomial no longer goes wild.  For standard linear regression we needed to reach a compromise: we want smaller bias but not to much variance.  For the smoothed method, no such compromise is needed. \n",
    "\n",
    "Step 3.2:  Comparing regular regression with smoothed regression\n",
    "--------\n",
    "Lets look at this closer by doing a head-to-head comparison with the two methods at the higher order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#      Customize the plot here\n",
    "#      =======================\n",
    "#   set poly order (default = last order from array)\n",
    "order = orders[-1]\n",
    "#  order = 20\n",
    "points = 50\n",
    "##############################\n",
    "\n",
    "legpoly = rd.LegPoly(order)\n",
    "\n",
    "pl.figure(figsize=bigcanvas)\n",
    "sp = 1\n",
    "pl.suptitle('Fitting different data sets of size '+str(points)+' and polys of order '+str(order))\n",
    "for useLegendre in [True,False]:\n",
    "  # plotting stuff:\n",
    "  #    plot the truth only, \n",
    "  #    not data since it varies per plot\n",
    "  pl.subplot(1,2,sp)\n",
    "  sp += 1\n",
    "  pl.plot(xts, yts,label = 'truth', linewidth=4)\n",
    "  pl.ylabel('y')\n",
    "  pl.xlabel('x')\n",
    "  pl.ylim(ydisplaymin,ydisplaymax)\n",
    "  pl.legend(bbox_to_anchor=(1, 1))\n",
    "  if useLegendre:\n",
    "        pl.title(\"Smoothed Legendre Polynomials\")\n",
    "  else:\n",
    "        pl.title(\"Simple Powers order\")\n",
    "  for sample in range(10):\n",
    "    # generate new data (x,y)\n",
    "    x = rd.makeX(points)\n",
    "    y = rd.addNoise(truefunc(x))\n",
    "    \n",
    "    # fit a polynomial then build a curve to plot using grid xts\n",
    "    if useLegendre: \n",
    "        # fit the polynomial\n",
    "        legpoly.fit(x,y)\n",
    "        #  build the fitted poly curve \n",
    "        ys = legpoly.apply(xts)\n",
    "    else:\n",
    "        #  build the fitted poly curve \n",
    "        ys = rd.linReg(x,y,xts,order)\n",
    "    \n",
    "    #  plot fitted curve\n",
    "    pl.plot(xts, ys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the fits with the Simple Powers versus the Smoothed Legendre Polynomials. How would you describe the difference?\n",
    "\n",
    "Step 3.3:  Seeing the fits converge\n",
    "------------\n",
    "So lets start with a small data set and gradually increase it, adding more data.  Now run our fitting algorithm on each in turn.  How does the sequence of fits look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#      Customize the plot here\n",
    "#      =======================\n",
    "#  increase data set by this each time\n",
    "growth = 0.6\n",
    "#  bounds on dataset size\n",
    "maxpoints = 500\n",
    "startpoints = 20\n",
    "#############################\n",
    "\n",
    "# make canvas size a bit bigger (in inches)\n",
    "pl.figure(figsize=[10,8])\n",
    "\n",
    "pl.plot(xts, yts,label = 'truth', linewidth=3.0)\n",
    "#   can be handy to modify the point size for data, \n",
    "#   use 2,4,6 depending on data set size\n",
    "pl.ylabel('y')\n",
    "pl.xlabel('x')\n",
    "        \n",
    "legpoly = rd.LegPoly(order) \n",
    "\n",
    "#  generate the starting data set\n",
    "points = startpoints\n",
    "x = rd.makeX(points)\n",
    "y = rd.addNoise(truefunc(x))\n",
    "\n",
    "#  keep stats about fits\n",
    "pointSeries = numpy.zeros(0)\n",
    "mseSeries = numpy.zeros(0)\n",
    "\n",
    "#  initial trial to find out maximum used points\n",
    "maxusedpoints = points\n",
    "while points<maxpoints:\n",
    "    newpoints = int(points*growth)\n",
    "    if newpoints<1:\n",
    "        newpoints = 1\n",
    "    maxusedpoints = points\n",
    "    points += newpoints\n",
    "    \n",
    "points = startpoints    \n",
    "while points<maxpoints:\n",
    "    y = rd.addNoise(truefunc(x))\n",
    "    # now, subsequently, we sample a new curve\n",
    "    legpoly.fit(x,y)\n",
    "    #  build the fitted poly curve \n",
    "    ys = legpoly.apply(xts)  \n",
    "    #   scale points to get a grey code\n",
    "    ccode = 0.9*numpy.log(1.0 + 100*(maxusedpoints-points)/(maxusedpoints-startpoints))/numpy.log(101.0)\n",
    "    #  plot fitted curve\n",
    "    pl.plot(xts, ys,linewidth=2, color=str(ccode),label=\"size = \"+str(points) )  \n",
    "    #  store results\n",
    "    pointSeries = numpy.append(pointSeries,points)\n",
    "    mseSeries = numpy.append(mseSeries,numpy.mean((yts-ys)*(yts-ys)))\n",
    "    #  increase the data set, bit of a hack\n",
    "    newpoints = int(points*growth)\n",
    "    if newpoints<1:\n",
    "        newpoints = 1\n",
    "    newx = rd.makeX(newpoints)\n",
    "    x = numpy.append(x,newx)\n",
    "    y = numpy.append(y,rd.addNoise(truefunc(newx)))\n",
    "    points += newpoints\n",
    "    \n",
    "#  the y range for the plot has to be altered depending on the data\n",
    "pl.ylim(ydisplaymin,ydisplaymax)\n",
    "\n",
    "# move the legend out of the way\n",
    "# the (1.2, 1.2) starts the legend at the location relative to\n",
    "# the top right corner\n",
    "pl.legend(bbox_to_anchor=(1.3, 1.1))\n",
    "pl.suptitle('A time series of fits on a growing sample')\n",
    "pl.show()\n",
    "\n",
    "pl.plot(pointSeries,mseSeries,'bo')\n",
    "pl.ylabel('mean square error')\n",
    "pl.xlabel('sample size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its instructive to change the number of data points used, from say from 10 upwards and look at the change in variability of the ensemble of functions.  In the first plot, as the fitted curve gets darker, which means it is based on more data, it gets closer and closer to the truth.  In the second plot, the mean squre error of the fitted curve with the truth decreases dramatically with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "RegressionLegendre.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
